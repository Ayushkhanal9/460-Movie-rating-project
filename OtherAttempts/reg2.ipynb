{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ayushkhanal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ayushkhanal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ayushkhanal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download NLTK resources\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from fractions import Fraction\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Label Distribution:\n",
      "review_label\n",
      "5    0.647059\n",
      "1    0.352941\n",
      "2    0.000000\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Data Label Distribution:\n",
      "review_label\n",
      "5    1.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "movieReviews = pd.read_csv('cleaned_reviews.csv', sep=',', header=None, names=['review_score', 'review_content'])\n",
    "movieReviews = movieReviews[~movieReviews['review_score'].str.contains('/')]\n",
    "movieReviews = movieReviews.drop(0)\n",
    "\n",
    "\n",
    "# Convert fractions to percentages\n",
    "movieReviews['review_score'] = movieReviews['review_score'].apply(lambda x: Fraction(x))\n",
    "movieReviews['review_score_percentage'] = movieReviews['review_score'] * 100\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0, 19, 39, 59, 79, 100]\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "movieReviews['review_label'] = pd.cut(movieReviews['review_score_percentage'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "def preprocess_text_and_tokenize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove punctuation and convert text to lowercase\n",
    "    text = text.apply(lambda sentence: re.sub('\\W', ' ', sentence).lower())\n",
    "    \n",
    "    # Tokenize and lemmatize using apply on each element\n",
    "    words = text.apply(lambda sentence: [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sentence)])\n",
    "    \n",
    "    # Flatten the list of lists\n",
    "    lemmatized_words = [word for sentence_words in words for word in sentence_words if word.isalpha() and word not in stop_words and word != '']\n",
    "    \n",
    "    return ' '.join(lemmatized_words)  # Join the words into a space-separated string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = train_test_split(movieReviews, test_size=0.1, random_state=42)\n",
    "\n",
    "# Display label distribution in training and test sets\n",
    "print(\"Training Data Label Distribution:\")\n",
    "print(train_data['review_label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest Data Label Distribution:\")\n",
    "print(test_data['review_label'].value_counts(normalize=True))\n",
    "\n",
    "# Apply preprocessing to the review content\n",
    "train_data['review_content'] = preprocess_text_and_tokenize(train_data['review_content'])\n",
    "test_data['review_content'] = preprocess_text_and_tokenize(test_data['review_content'])\n",
    "\n",
    "# Tokenize and build vocabulary using lemmatization\n",
    "all_words = ' '.join(train_data['review_content'])\n",
    "vocabulary = set(word_tokenize(all_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy on the test set: 100.00%\n",
      "\n",
      "Test Data with Predicted Ratings:\n",
      "      review_label  lr_predicted_rating  \\\n",
      "57225            5                    5   \n",
      "\n",
      "                                          review_content  \n",
      "57225  thriller sobering enough graphic portrayal for...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression parameters\n",
    "alpha = 0.06\n",
    "\n",
    "# Initiate parameters\n",
    "lr_parameters_per_rating = {rating: Counter() for rating in range(1, 6)}\n",
    "\n",
    "# Calculate Logistic Regression parameters\n",
    "for rating in range(1, 6):\n",
    "    rating_data = train_data[train_data['review_label'] == rating]['review_content']\n",
    "    n_rating = len(rating_data)\n",
    "    \n",
    "    # Count occurrences of each word in the entire column\n",
    "    word_counts = Counter(' '.join(rating_data).split())\n",
    "    \n",
    "    for word in vocabulary:\n",
    "        n_word_given_rating = word_counts[word]\n",
    "        p_word_given_rating = (n_word_given_rating + alpha) / (n_rating + alpha * len(vocabulary))\n",
    "        lr_parameters_per_rating[rating][word] = p_word_given_rating\n",
    "\n",
    "\n",
    "# Logistic Regression classifier\n",
    "import numpy as np\n",
    "\n",
    "# Logistic Regression classifier\n",
    "def lr_predict_rating(review, parameters, n_rating, alpha, vocabulary, lemmatizer, stop_words):\n",
    "    words = word_tokenize(review)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "    # Initialize log probabilities with prior log probabilities\n",
    "    log_probabilities = {rating: np.log(1) for rating in parameters.keys()}\n",
    "    \n",
    "    for word in lemmatized_words:\n",
    "        for rating, word_params in parameters.items():\n",
    "            p_word_given_rating = word_params.get(word, alpha / (n_rating + alpha * len(vocabulary)))\n",
    "            log_probabilities[rating] += np.log(p_word_given_rating)\n",
    "\n",
    "    # Choose the rating with the highest log probability\n",
    "    predicted_rating = max(log_probabilities, key=log_probabilities.get)\n",
    "    return predicted_rating\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test_data['lr_predicted_rating'] = test_data['review_content'].apply(lambda x: lr_predict_rating(x, lr_parameters_per_rating, len(train_data), alpha, vocabulary, lemmatizer, stop_words))\n",
    "# Remove rows with NaN values in 'review_label'\n",
    "test_data = test_data.dropna(subset=['review_label', 'lr_predicted_rating'])\n",
    "\n",
    "# Evaluate the Logistic Regression accuracy\n",
    "lr_accuracy = accuracy_score(test_data['review_label'], test_data['lr_predicted_rating'])\n",
    "print(f\"\\nLogistic Regression Accuracy on the test set: {lr_accuracy:.2%}\")\n",
    "\n",
    "# Display the first few rows of the test set with predictions\n",
    "print(\"\\nTest Data with Predicted Ratings:\")\n",
    "print(test_data[['review_label', 'lr_predicted_rating', 'review_content']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Predicted Rating: 5\n",
      "Logistic Regression Predicted Rating: 5\n",
      "Logistic Regression Predicted Rating: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def classify_movie_review_rating(review, n_rating, alpha, vocabulary, lr_parameters_per_rating):\n",
    "    review = re.sub('\\W', ' ', review)\n",
    "    review = review.lower().split()\n",
    "\n",
    "    probabilities = {rating: 1 for rating in range(1, 6)}  # Assuming ratings are 1 to 5\n",
    "\n",
    "    for word in review:\n",
    "        for rating, word_params in lr_parameters_per_rating.items():\n",
    "            p_word_given_rating = word_params.get(word, alpha / (n_rating + alpha * len(vocabulary)))\n",
    "            probabilities[rating] *= p_word_given_rating\n",
    "\n",
    "    # Choose the rating with the highest probability\n",
    "    predicted_rating = max(probabilities, key=probabilities.get)\n",
    "    \n",
    "    return predicted_rating\n",
    "\n",
    "# Example usage with a movie review\n",
    "example_review = \"This movie was amazing! I loved it.\"\n",
    "lr_predicted_rating = classify_movie_review_rating(example_review, len(train_data), alpha, vocabulary, lr_parameters_per_rating)\n",
    "print('Logistic Regression Predicted Rating:', lr_predicted_rating)\n",
    "\n",
    "example_review = \"This movie sucks\"\n",
    "lr_predicted_rating = classify_movie_review_rating(example_review, len(train_data), alpha, vocabulary, lr_parameters_per_rating)\n",
    "print('Logistic Regression Predicted Rating:', lr_predicted_rating)\n",
    "\n",
    "example_review = \"This movie was ok\"\n",
    "lr_predicted_rating = classify_movie_review_rating(example_review, len(train_data), alpha, vocabulary, lr_parameters_per_rating)\n",
    "print('Logistic Regression Predicted Rating:', lr_predicted_rating)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
